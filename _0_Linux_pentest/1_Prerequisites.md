# General approach
Whatever the starting point, a product evaluation is not a CTF! The evaluator has more information (and access) than the attacker. This is the reason why an evaluator spending only 2 weeks on a product is able to say that the product will resist 3 months of analysis by an atacker with the same skillset.

Consequently the evaluator **must** leverage any advantages they have over a blackbox situation,: documentation, root access on the TOE, etc. 

On the other hand, CC requires the developer to provide information. The standard does require a complete and meaningful documentation, but in a manner that is technology agnostic: this often results in a documentation that mindlessly tries to meet CC requirements contextualizing/tailoring the requirement for the specific TOE type. This ultimately leads to a documentation that will be useless for AVA_VAN purpose. 

This method refines the CC requirements for linux TOEs in order to ensure the evaluator gets meaningful information when starting AVA_VAN activities. 

# Evaluation of available Documentation

In a CC evaluation, for each topic, the evaluator will first try to determine whether the ADV documentation is sufficiently clear. In a second step, the evaluator will check that the TOE conforms to this description. This second check should preferably be performed during the ADV review if the TOE is already available, but can be performed later.

As a rule of thumb, the evaluator should be able to select a given asset (e.g. user data DATA, transmitted to the TOE over the network) and check whether they can easily:  
 - Identify the TSFI by which DATA arrives on the TOE (ADV_FSP)
 - Identify which process/daemon/service holds DATA in memory? which files/sockets hold DATA? which users can access it? (ADV_TDS)
	 - are these components proprietary or pure upstream open source, and in which versions? (ALC_CMS) 
 - Identify which process/daemon/service control the information flow allowing DATA to pass (ADV_ARC)? 
 - etc.

## ALC_CMS
### CC refinements for a linux-based TOE
As a general rule, these requirements identify various *static parts* of the TOE

### Summary: for an ALC_CMS to PASS
We expect the following table:

| Item | Type | Version | Upstream ?|Developer|
|:---- |:---- |:----    |:----      | :----   | 
| ...  | ...  | ...     | ...       |  ...    | 

Note: 
 - The list should allow to indentify the ID and versions of any upstream component (kernel, distro, programs, libs...), even if it has been patched aftrewards.
 - "upstream" classification can be more subtle, but th eminimum is to distinguish 
	 - Upstream: pure upstream components from the base OS repos
	 - Non-upstream: components added from other repos, or patched/developed by the TOE developer.
 - Item granularity: for non-upstream items, the list should be done at the file level (source code ). External dependencies may be recovered with a larger granularity (e.g. a closed source COTS .so library, or an open source RPM package).

## ADV_TDS.3
### CC refinements for a linux-based TOE

As a general rule, on a linux-based TOE:
 - *Modules* are **processes, daemons or services** executing on the TOE.
 - For each module, the developer should be able to describe the following *Interactions* means:
	 - The initialization parameters of the module: 
		 - configuration files and environment variables used by the module
		 - variables/flags used when starting the module
		 - privileges of the module (kernel/root/user)
	 - user interface: CLI, GUI... (relevant only for processes)
	 - IPCs: signals, sockets/dbus, pipes, message queues, semaphores, shared files and shared memory
	 - network communication: network sockets
 - a *Subsystem* can be anything from a process/daemon/service to a whole linux Kernel. The amount and hierarchy of subsystems is to the developer to decide - this level of description is mostly meant to improve readability. 

On top of existing documentation, the evaluator should classify modules as either *upstream* and *non-upstream*, in order to include or exclude it from parts of the analysis:
 - what is proprietary?
 - what is open source or COTS, from which origin?
	 - on these parts, what has been patched by the developer?


NB:
 - We want to focus the AVA analysis on parts that have been patched/developed by the developer. 
pure "upstream" programs can be partly skipped in the context of an AVA_VAN.3: 
	 - we do not expect to be able to find vulnerabilities in the design or the implementation of a linux kernel or OpenSSL in the constraint time of an evaluation (although lesser-known or obscure open source libraries will be considered as *non-upstream*, same as proprietary parts)
	 - the evaluator will therefore focus on configuration and CVEs
 - a similar logic applies to crypto or network protocols - any *recognized* protocol (known RFCs or ISO std, algorithms recognized by the certification scheme, etc.) will be considered as having a secure design by default. We will only concentrate on the configuration and implementation.

One problem of CC is that there is not required mapping between "configuration items" and "subsystems" or "modules". In order to perform this mapping, the evaluator may in some cases have to:
 - manually map configuration items to the source code (e.g. using makefiles) 
 - identify for all modules whether they are completely implemented by upstream source code, using the developer mapping from design to implementation (ADV_IMP.1)
 
This can be a very time-intensive process. It is advised to discuss it as early as possible with the developer, so that they provide usable information right from the bat.

### Summary: for an ADV_TDS to PASS

When claiming a PASS, the evaluator should be able to describe all modules and interactions as follows:

*Modules:*

|Module|Type |SFR relevance |Upstream?|Env variables|config files|variables/flags|privileges|See details in section|
|:---- |:----|:----         |:----    |:----        |:----       |:----          |:----     |:----                 |  
|      |...  | ...          |         | ...         | ...        |...            | ...      | ...                  |  
Note: 
 - type may be daemon, service, or process (which itself may include bash script, program, etc.)
 - SFR relevance means enforcing/supporting/non-interfering
 - privileges are typically mapped on the security domains described in ADV_ARC: Kernel/root/user and SUID/GID, possibly more (should the developer define more in ADV_ARC) 


*Shared files:*
|Shared file|File permissions|Used with modules|See behaviour in section|
|:----      |:----           |:----            |:----                   |
| ...       | ...            | ...             |...                     |

*Signals:*
|Signals|Used with modules|See behaviour in section|
|:----  |:----            |:----                   |
| ...   | ...             | ...                    |

*IPC and network sockets:* to be used for: 
 - sockets: USD, berkeley, network sockets...
 - anonymous / named pipes, network socket,
 - POSIX/System V message queues, 
 - other such as dbus...
 - Shared memory, 
 - other: process_vm_readv...

|channel|Type |Used w/ modules|Permissions of the channel|Protection in the channel|See details in section|
|:----  |:----|:----          |:----                     |:----                    |:----                 |
| ...   | ... | ...        |  |	...                      | ...                     | ...                  |

Notes:
 - *Permissions of the channel* is usually the set of permissions of the file descriptor used to transmit data (e.g. in named pipes or sockets). It can also be the set of permissions of a message queue  
 - *Protection in the channel* refers to additional protection, e.g. server-side credential or PID checking, use of encryption, etc.



## ADV_FSP 
### CC refinements for a linux-based TOE
TSFIs happen at the limit of the TOE. As a general rule, they should be described as two different sets:
 - physical interfaces : USB, KMS...
 - network interfaces : ethernet, wireless

We will assume here that as in most SW evaluations, the physical interfaces are trusted, and that we will only care about the network interfaces. They need to be described at every (meaningful) layer - in most cases it will result in a table that loks like a network scan.

#### Summary: for an FSP to PASS
The following type of table is expected:

| TSFI   | port | Data link  | Internet | Transport | Applicative | Corresp. module | Details in section |
|:----   |:---- |:----       |:----     |:----      |:----        |:----            |:----               |
| ...    | ...  | ...        | ...      |           |	...       | ...             | ...                |
| SSH    |  22  | 802.03/eth | IPv4/v6  | TCP       | SSH v2      | sshd            | ...                |
| VPN    |  500 for IKE, 1500 for IPSec NAT-T  | 802.03/eth | IPSec/ESP in transport mode on IPv6 only (no IPv4), with the following cipher suites: etc.  | UDP       | proprietary VPN app      | Module X            | ...                |
| NTP   |  123  | 802.03/eth | IPv4/v6  | UDP       | NTP v3      | ...            | ...                |
| DHCP client   |  68  | 802.03/eth | IPv4/v6  | UDP       | DHCP/RFC 2131     | ...            | ...                |
|   ... | ...   | wifi/802.11 *with WPA2/802.11i (WEP not supported) | IPv4/v6  | ...       | ...       | ...            | ...                |


## ADV_ARC.1
### CC refinements for a linux-based TOE

*Security domains:* we expect at least 
 - whether the TOE only uses linux default security domains (kernel/root/users and SUID/GID mechanisms) or whether it defines additional domains (capabilities, SELinux contexts, sandboxing, virtualization, etc.)
	 - an explanation of which modules run in each security domain
	 - a list of all users and groups, with their respective privileges (esp. access to sudo/su)
		 - the password Policy for users, and how (by which means) it is enforced?
		 - How are users identified/authenticated/authorized?
	 - an explanation of how intermodule interactions within a domain are protected against other domains (e.g. named pipe is protected by permissions set to the current user, and ptrace is set to 3 to forbid other users to peek in the names pipe file)
	 - an explanation of the authorized points of contact between domains
 - A description of the filesystem of the TOE, and the associated permissions (incl. nosuid, nodev, noexec)
 - A description of all drives, their intended use and how credentials are used, if any

*Non-bypassability:* we exepct
 - Hardening: Which hardening measures are used? (Yama ptrace scope, AppArmor, grsec, PaX, Execshield, SELinux, ASLR...)

*Self-protection:*
 - Describe which firewalling features are in place on the TOE (e.g. iptables, ufw...) and explain their default configuration
 - List the third-parties that are expected to be connected to the TOE through the network:
	 - does the product use a third-party SSO? 
	 - PKI services such as OCSP?<br> 
	 - does the product rely on an external NTP, etc.?<br> 
	 - does the product rely on a back office for licensing, product updates?
	 - does the product rely on repositories to update 3rd party building blocks (distro, libraries...)?
	 - etc.
  For all these third-parties, explain how the endpoints or payload are identified/authenticated, protected against tampering or eavesdropping, etc. 




**Example**: if the TOE uses OpenSSL to create a TLS trusted channel the target of the attacker would be as follows:
 - cleartext traffic is likely to be accessible only in the memory of the process that uses the SSL_read or SSL_write, while only encrypted traffic appears in the socket used by OpenSSL. 
 - the config file to target would mainly be openssl.cnf, but also the potential config files of the applications that make use of openSSL.


# Additional information gathering 

## Inventory scripts to run on the TOE 

Logged in as root on the TOE, run 
 - the [Low hanging fruits script](_0_System_AVA_testing\_resources\Low_hanging_fruits.sh): ````sudo ./Low_hanging_fruits.sh > Low_hanging_fruits.md````
 - the [Identification script](_0_System_AVA_testing\_resources\Identification.sh): ````sudo ./Identification.sh > Identification.md````


## Inventory of network services
The network scan is often the first step in a CTF or black-box pentest. In a CC evaluation, it is way less crucial as a first step, since the interfaces of the TOE are supposedly already described in detail in ADV_FSP. This step is however crucial in order to check that the TOE *complies to its own documentation*.

### Listening services
#### Network scan 
AVD_TDS should describe the Supported protocols at the applicative layer, which means that even before the network scan, the evaluator should know which ports are used, for which service, using which protocol(s). The network scan is normally only made to check potential discrepancies.

Starting from an anonymous access (no UDP research by default)
````nmap -n -T4 -sV <IP>```` coresponds to a very quick scan on most used ports: it should only be used on an easy challenge that is likely to expose low hanging fruits
If there is a minimum level of coverage expected, use ````nmap -n -T4 -p 1-65535 -sS <IP>````... then adapt
 - if the TOE seems to have a reasonable attack surface, try a slow comprehensive scan
````nmap -sS -sU -A -v -PE -PP -PS80,443 -PA3389 -PU40125 -PY -g 53 --script "default or (discovery and safe)" <IP>````
 - if not, clarify with the developer why the surface is so large

NB: explanations
 - -n/-R: Never/Always do DNS resolution (here we don't resolve because we address the IP)
 - -T<0-5>: Set timing template (higher is faster): here we try to do a "fast scan"
 - -p 1-65535 : all possible ports
 - -sS : TCP SYN


[TODO]: elaborate on the choice of options... See alternative proposals courtesy of Hacktricks
````
# Nmap fast scan for the most 1000tcp ports used
nmap -sV -sC -O -T4 -n -Pn -oA fastscan <IP> 
# Nmap fast scan for all the ports
nmap -sV -sC -O -T4 -n -Pn -p- -oA fullfastscan <IP> 
# Nmap fast scan for all the ports slower to avoid failures due to -T4
nmap -sV -sC -O -p- -n -Pn -oA fullscan <IP>
#Bettercap Scan
syn.scan 192.168.1.0/24 1 10000 #Ports 1-10000
````
And for UDP:
````
# Check if any of the most common udp services is running
udp-proto-scanner.pl <IP> 
# Nmap fast check if any of the 100 most common UDP services is running
nmap -sU -sV --version-intensity 0 -n -F -T4 <IP>
# Nmap check if any of the 100 most common UDP services is running and launch defaults scripts
nmap -sU -sV -sC -n -F -T4 <IP> 
# Nmap "fast" top 1000 UDP ports
nmap -sU -sV --version-intensity 0 -n -T4 <IP>
# You could use nmap to test all the UDP ports, but that will take a lot of time
````


#### Whitebox shortcut
````
sudo netstat -tulpn 
````
NB:
it may be useful to identify all connections (not only the ones listening) in case some network client on the TOE could open a vulnerable channel: 
````
sudo netstat -tuapn 
````


### Searching for other possible connections from the TOE
The verification of listening services is not enough and many other conections may be created on-demand! confront what you can find on the TOE to the description in ADV
For example 'apt' will create a client to connect to repos, and it will not appear in the listening services - What happens if
 - the repo is accessed in http (which is frequent) **and** does not sign packages? (which should not happen)
 - the repo is unofficial, untrusted and may well be considered compromised by default?

[TODO]: How to search independently for such possible on-demand accesses? 
 - bad idea: listen on wireshark during the whole ATE tests. why is it a bad idea? even `apt` may be considered a non interfering feature and not tested/used during ATE
 - search for http: ftp: in config files, e.g. ````sudo find /etc/ -type f -exec grep -H 'http:' {} \;````? 
 - check nginx settings for https configs and /etc/xxx/ssl + /etc/xxx/xxx.conf.d for keys 
 - etc

### The special case of third-party services used by the TOE	

Third party services used by the TOE are possible attack vectors, especially when they are trusted by design or even roots of trust. We will not detail the possible attack scenarios, though, because in the context of a CC evaluation, such third-parties are trusted by assumptions. What needs to be checked, though, is:
 - the completeness of the ST and AGD docuÃ¶ents:
	 - does the product use a third-party SSO? PKI?
	 - does the product rely on a back office for licensing, product updates? is the channel safe? 
	 - does the product rely on repositories to update 3rd party building blocks (distro, libraries...)? does it use non official repositories? 
	 - etc.
 - the security of the connection to all these third-parties


## Expected results and next steps


The evaluator shall now be able to
 - Draw an inventory of the TOE:
	 - Potential low-hanging fruits (i.e. easily accessible vulnerabiities at the system level) -> See the output of the *Low hanging fruits* script 
	 - Main features at the system level (users, filesystem, privileged processes, hardening measures...) -> See the output of the *Inventory* script
	 - Open ports and the corresponding network services -> see the output of the network inventory 
 - Check potential discrepancies between the inventory and ADV_TDS/FSP/ARC and ALC_LCD - notably check, for each component, whether it is:
	 - a well known open source component (possibly patched by the developer)
	 - anything other that that: open source but not well known, downright shady source, or simply proprietary developement
 - List privileged processed and network services, and classify them as :
	 - *TSF relevant* : services (and traffic) pertaining to the trusted path to authenticated users, or protected communications with other IT Products. This can be plaintext (e.g. a simple HTTP session) or encrypted (e.g. TLS records). This obviously includes *underlying layers* (e.g. the TCP/IP layer under the TLS session, ICMP, DNS...)
	 - *non TSF relevant* (e.g. an additional HTTP service not directly related to the user session) - check if these items run with significant privileges (for example, if a network service runs as root, or if it gives a full session to the user, e.g. ssh)
	 - *no impact on TSF*: this will probably rarely exist in practice: these are the parts that would not have an impact on the TSF even if they were compromised/malicious (e.g. an antivirus contained in a VM, on a larger TSF)

Most importantly, **comment any discrepancy and clarify with the developer**.

The following table maps the resources the evaluator should take into account for each *non-upstream* item identified (privileged process, privileged or unprivileged network service). 

|Test/review the...                             |Protocol|Design|Config|Code|CVEs|
|:----                                          |:----   |  :---|:---  |:---|:---|
|TSF relevant                                   |Yes     |Yes   |Yes   |Yes |Yes |
|Non-TSF process or network service (privileged)|No      |No    |Yes   |Yes |Yes |
|Non-TSF network service (non-privileged)       |No      |No    |Yes   |Yes |Yes |
|no impact on TSF                               |No      |No    |No    |No  |No  |

For the upstream components, no need for a table: protocols, design and code are *not* reviewed. Only the configuration and public vulnerabilities are checked, and it can even be skipped if the componment has no impact on TSF.

NB:
 - This table is constrained by the CC requirements themselves (TSF non interfering parts are less documented, even if they are running with privileges on the TOE). It would make sense to review the specs of protocols landing on privileged services on the TOE, regardless of their relationship to the TSF, because they cam lead to privilege escalation. HOwever, specifications may not be available due to CC requirements themselves, and the evaluator (unfortunately) cannot bend the standard to their will.


### Public vulnerabilities

Perform a [Public vulnerability analysis](../../../Pentesting/Pentesting%20methods%20and%20tools/Public%20vulnerability%20analysis/Public%20vulnerability%20analysis%20101.md) on the following parts
